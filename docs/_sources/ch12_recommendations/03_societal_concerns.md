# Societal Concerns with Recommendation Algorithms
Let's now look at some larger societal concerns with the effects of recommendation algorithms

## [Epistemic Bubbles / Echo Chambers](https://en.wikipedia.org/wiki/Echo_chamber_(media)#Echo_chambers_vs_epistemic_bubbles)
- Connections and conversations can exclude some perspectives (whether intentional or not)
  - Ideas and views get repeated without challenge or alternatives
- This allows groups to freely have conversations among themselves without external challenge. These groups may range from:
  - Hate groups
  - Fan groups
  - Marginalized communities (e.g., [safe spaces](https://en.wikipedia.org/wiki/Safe_space))
- Increases polarization
  - In some ways, this is the opposite of context collapse, where the insider/outsider context never collapses
- Alternate theory: https://www.pnas.org/doi/10.1073/pnas.2207159119

## Amplifying Polarization and Negativity
- If social media sites simply amplify content that gets strong reactions, they will often amplify the most negative and polarizing content.
  - [Five points for anger, one for a ‘like’: How Facebook’s formula fostered rage and misinformation](https://www.washingtonpost.com/technology/2021/10/26/facebook-angry-emoji-algorithm/)
  - [Twitter's algorithm might amplify 'ratioed' conservatives.](https://www.msnbc.com/opinion/twitter-s-algorithm-might-amplify-ratioed-conservatives-time-rethink-dunking-n1283364)
    - “An analysis [...] suggested that when users swarm tweets to denounce them with quote tweets and replies, they might be cueing Twitter’s algorithm to see them as particularly engaging, which in turn might be prompting Twitter to amplify those tweets. The upshot is that when people enthusiastically gather to denounce the latest Bad Tweet of the Day, they may actually be ensuring more people see it than had they never decided to pile on in the first place.
    - That possibility raises serious questions of what constitutes responsible civic behavior on Twitter and whether the platform is in yet another way incentivizing combative behavior.”
  - [According to Twitter, Twitter’s algorithm favours conservatives](https://www.economist.com/graphic-detail/2021/11/13/according-to-twitter-twitters-algorithm-favours-conservatives) ([copy on archive.org](https://web.archive.org/web/20220106162108/https://www.economist.com/graphic-detail/2021/11/13/according-to-twitter-twitters-algorithm-favours-conservatives))
    - “Whereas Google gave higher rankings to more reliable sites, we found that Twitter boosted the least reliable sources, regardless of their politics.”

see also: [Cable news has a much bigger effect on America’s polarization than social media, study finds](https://www.niemanlab.org/2022/08/cable-news-has-a-much-bigger-effect-on-americas-polarization-than-social-media-study-finds/)

## Radicalization:  Rohingya Genocide in Myanmar since 2016
- [Facebook admits it was used to 'incite offline violence' in Myanmar](https://www.bbc.com/news/world-asia-46105934)  (2018, BBC)
- [Rohingya sue Facebook for £150bn over Myanmar genocide](https://www.theguardian.com/technology/2021/dec/06/rohingya-sue-facebook-myanmar-genocide-us-uk-legal-action-social-media-violence) (2021, The Guardian)
  - Facebook’s negligence facilitated the genocide of Rohingya Muslims in Myanmar after the social media network’s algorithms amplified hate speech and the platform failed to take down inflammatory posts, according to legal action launched in the US and the UK.

## Radicalization: The Flat Earth Movement
- Flat Earth:
  - “Flat Earth is a belief that the earth isn’t a globe, but is actually flat, a fact that has been kept from Us, meaning normal people, by a nebulous, powerful Them for nefarious, inscrutable purposes.”
    - [In Search of a Flat Earth](https://youtu.be/JTfhYyTuT44?t=1151) (19:11-19:27) - Dan Olson - Folding Ideas
- YouTube’s role in creating this movement:
  - “Modern Flat Earth [movement] was essentially created by content algorithms trying to maximize retention and engagement by serving users suggestions for things that are, effectively, incrementally more concentrated versions of the thing they were already looking at. Bizarre cranks peddling random theories are an aspect of civilization that has always been with us, so it was inevitable that they would end up on YouTube, but the algorithm made sure they found an audience. These systems were accidentally identifying people susceptible to conspiratorial and reactionary thinking and sending them increasingly deeper into Flat Earth evangelism.”
    - [In Search of a Flat Earth](https://www.youtube.com/watch?v=JTfhYyTuT44&t=2077s) (34:37 - 37:40) - Dan Olson - Folding Ideas
- More Info: [YouTube aids flat earth conspiracy theorists, research suggests](https://www.bbc.com/news/technology-47279253 )

## Discussion Questions
- What responsibilities do you think social media platforms should have in regards to larger social trends?
- What strategies do you think might work to improve how social media platforms use recommendations?


- Consequentialism (impact vs intent)
