# Mental Health Detection

Since social media platforms are able to gather so much data on their users, they can try to use data mining to figure out information about their users' moods, mental health problems, or neurotypes (e.g., ADHD, autism).

For example, Facebook has a suicide detection algorithm, where they try to intervene if they think a user is suicidal ([Inside Facebook's suicide algorithm: Here's how the company uses artificial intelligence to predict your mental state from your posts](https://www.businessinsider.com/facebook-is-using-ai-to-try-to-predict-if-youre-suicidal-2018-12)). As social media companies have tried to detect talk of suicide and sometimes remove content that mentions it, users have found ways of getting around this by inventing new word uses, like "[unalive](https://knowyourmeme.com/memes/unalive)."

Larger efforts at trying to determine emotions or mental health through things like social media use, or [iPhone or iWatch use](https://www.cnbc.com/2020/08/04/apple-ucla-to-study-depression.html), have had very questionable results, and [any claims of being able to detect emotions reliably are probably false](https://www.nature.com/articles/d41586-021-00868-5).
